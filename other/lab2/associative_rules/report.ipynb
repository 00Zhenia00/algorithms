{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eaf6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754c87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.ml.associative_rules.AprioriModel import AprioriModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51c13ef",
   "metadata": {},
   "source": [
    "### Correctness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc4b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [\n",
    "    ['a', 'b', 'c', 'd', 'e'],\n",
    "    ['a', 'c', 'd', 'f'],\n",
    "    ['a', 'b', 'c', 'd', 'e', 'g'],\n",
    "    ['c', 'd', 'e', 'f'],\n",
    "    ['c','e', 'f', 'h'],\n",
    "    ['d', 'e', 'f'],\n",
    "    ['a', 'f', 'g'],\n",
    "    ['d', 'e', 'g', 'h'],\n",
    "    ['a', 'b', 'c', 'f'],\n",
    "    ['c', 'd', 'e', 'h'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac527a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<algorithms.ml.associative_rules.AprioriModel.AprioriModel at 0x1f56d704610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and run Apriori\n",
    "apriori = AprioriModel(min_support=0.4, min_confidence=0.6)\n",
    "apriori.fit(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fbd021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "{'a'}: 0.50\n",
      "{'c'}: 0.70\n",
      "{'d'}: 0.70\n",
      "{'e'}: 0.70\n",
      "{'f'}: 0.60\n",
      "{'a', 'c'}: 0.40\n",
      "{'c', 'd'}: 0.50\n",
      "{'e', 'c'}: 0.50\n",
      "{'e', 'd'}: 0.60\n",
      "{'c', 'f'}: 0.40\n",
      "{'e', 'c', 'd'}: 0.40\n"
     ]
    }
   ],
   "source": [
    "# Print frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "for k, itemsets in apriori.get_frequent_itemsets().items():\n",
    "    for itemset, support in itemsets.items():\n",
    "        print(f\"{set(itemset)}: {support:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7c28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "{'a'} => {'c'}\n",
      "Support: 0.40, Confidence: 0.80, Lift: 1.14\n",
      "\n",
      "{'c'} => {'d'}\n",
      "Support: 0.50, Confidence: 0.71, Lift: 1.02\n",
      "\n",
      "{'d'} => {'c'}\n",
      "Support: 0.50, Confidence: 0.71, Lift: 1.02\n",
      "\n",
      "{'e'} => {'c'}\n",
      "Support: 0.50, Confidence: 0.71, Lift: 1.02\n",
      "\n",
      "{'c'} => {'e'}\n",
      "Support: 0.50, Confidence: 0.71, Lift: 1.02\n",
      "\n",
      "{'e'} => {'d'}\n",
      "Support: 0.60, Confidence: 0.86, Lift: 1.22\n",
      "\n",
      "{'d'} => {'e'}\n",
      "Support: 0.60, Confidence: 0.86, Lift: 1.22\n",
      "\n",
      "{'f'} => {'c'}\n",
      "Support: 0.40, Confidence: 0.67, Lift: 0.95\n",
      "\n",
      "{'e', 'c'} => {'d'}\n",
      "Support: 0.40, Confidence: 0.80, Lift: 1.14\n",
      "\n",
      "{'e', 'd'} => {'c'}\n",
      "Support: 0.40, Confidence: 0.67, Lift: 0.95\n",
      "\n",
      "{'c', 'd'} => {'e'}\n",
      "Support: 0.40, Confidence: 0.80, Lift: 1.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for rule in apriori.get_association_rules():\n",
    "    print(f\"{rule['antecedent']} => {rule['consequent']}\")\n",
    "    print(f\"Support: {rule['support']:.2f}, Confidence: {rule['confidence']:.2f}, Lift: {rule['lift']:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241519be",
   "metadata": {},
   "source": [
    "### Execution time check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b13016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom AprioriModel execution time: 0.7671 seconds\n",
      "sklearn/mlxtend Apriori execution time: 0.0173 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori as skl_apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import random\n",
    "\n",
    "# Generate synthetic transaction data\n",
    "def generate_transactions(num_transactions, num_items, max_items_per_transaction):\n",
    "    items = [f'item_{i}' for i in range(num_items)]\n",
    "    transactions = []\n",
    "    for _ in range(num_transactions):\n",
    "        transaction_length = random.randint(1, max_items_per_transaction)\n",
    "        transaction = random.sample(items, transaction_length)\n",
    "        transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "large_transactions = generate_transactions(5000, 50, 10)\n",
    "\n",
    "# Time custom AprioriModel\n",
    "start = time.time()\n",
    "apriori_large = AprioriModel(min_support=0.1, min_confidence=0.5)\n",
    "apriori_large.fit(large_transactions)\n",
    "my_apriori_time = time.time() - start\n",
    "\n",
    "# Prepare data for mlxtend apriori\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(large_transactions)\n",
    "df_large = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Time sklearn/mlxtend apriori\n",
    "start = time.time()\n",
    "frequent_itemsets = skl_apriori(df_large, min_support=0.1, use_colnames=True)\n",
    "sklearn_apriori_time = time.time() - start\n",
    "\n",
    "print(f\"Custom AprioriModel execution time: {my_apriori_time:.4f} seconds\")\n",
    "print(f\"sklearn/mlxtend Apriori execution time: {sklearn_apriori_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca64eb7",
   "metadata": {},
   "source": [
    "---\n",
    "Comment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ff38b",
   "metadata": {},
   "source": [
    "### Why my implementation is slower?\n",
    "\n",
    "My implementation:\n",
    "- Uses Python sets and frozensets which have overhead\n",
    "- Uses defaultdict and combinations which add some computational cost\n",
    "- Checks all subsets in candidate generation (all_subsets_frequent)\n",
    "\n",
    "mlxtend implementation:\n",
    "- Uses more efficient data structures (like pandas df, bitmaps, numpy arrays)\n",
    "- Implements smarter candidate generation that avoids checking all subsets\n",
    "- Uses optimized counting methods\n",
    "- Critical performance sections are often written in Cython or might call underlying C/Fortran libraries (via NumPy). This dramatically reduces the Python interpreter overhead and leads to much faster execution speeds for numerical computations and iterative processes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
